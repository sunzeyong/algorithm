# algorithm

> 多写算法，保持脑力，预防阿尔兹海默症！  

数据结构和算法相辅相成，数据结构为算法服务，算法要作用在特定的数据结构之上。


## 复杂度分析
数据结构和算法解决是“如何让计算机更快时间、更省空间的解决问题”，因此需从执行时间和占用空间两个维度来评估数据结构和算法的性能。
复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。

### 大O复杂度表示法
为了粗略估计算法代码执行时间，这里假设每行代码执行时间都是一样的，得到所有代码的执行时间T(n)与每行代码的执行次数n成正比，我们可以把这个规则总结成一个公式，即 T(n) = O(f(n))  
T(n):表示代码执行时间；f(n):表示代码执行的次数总和；O:表示执行时间和执行次数总和成正比  
举个例子T(n)=O(2n+1), T(n)=O(2n^2+2n+3)
大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。  
当n很大时，公式中的低阶、常量、系数部分并不左右增长趋势，所以都可以忽略。上述例子就可以记为T(n)=O(n), T(n)=O(n^2)

### 时间复杂度分析
常见的复杂度量级有 常量阶O(1) 对数阶O(lngn) 线性阶O(n) 线性对数阶O(nlogn) 平方阶O(n^2) 立方阶O(n^3) k次方阶O(n^k) 指数阶O(2^n) 阶乘阶O(n!)  
对于刚罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个：O(2^n) 和 O(n!)。

1. O(1)  
一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)

2. O(logn) O(nlogn)  
```
i=1;
 while (i <= n)  {
   i = i * 2;
 }
```
在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 O(logn)

3. O(m+n) O(m*n)  
```
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }
 
  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }
 
  return sum_1 + sum_2;
}
```
当代码由两个数据规模，并且无法评估m和n谁的量级大，在表示复杂度时就不能简单的利用加法法则，省略掉其中一个，所以上面的复杂度就是O(m+n)


### 空间复杂度分析
时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。我们常见的空间复杂度就是 O(1)、O(n)、O(n2 )，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到


### 几个复杂度分析相关概念
最好情况时间复杂度、最坏情况时间复杂度、平均情况时间复杂度、均摊时间复杂度。之所以引入这几个复杂度概念，是因为，同一段代码，在不同输入的情况下，复杂度量级有可能是不一样的。

```
// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
```
为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。  
最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。就像我们刚刚讲到的，在最理想的情况下，要查找的变量 x 正好是数组的第一个元素，这个时候对应的时间复杂度就是最好情况时间复杂度。  
最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。就像刚举的那个例子，如果数组中没有要查找的变量 x，我们需要把整个数组都遍历一遍才行，所以这种最糟糕情况下对应的时间复杂度就是最坏情况时间复杂度。  

平均情况时间复杂度全称是加权平均时间复杂度或者期望时间复杂度，因为每个情况发生的概率不一定一样，需要将各种情况发生大概率考虑进去。

```
// array 表示一个长度为 n 的数组
 // 代码中的 array.length 就等于 n
 int[] array = new int[n];
 int count = 0;
 
 void insert(int val) {
    if (count == array.length) {
       int sum = 0;
       for (int i = 0; i < array.length; ++i) {
          sum = sum + array[i];
       }
       array[0] = sum;
       count = 1;
    }
 
    array[count] = val;
    ++count;
 }
```
每一次 O(n) 的插入操作，都会跟着 n-1 次 O(1) 的插入操作，所以把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)。这就是均摊分析的大致思路。  
对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

## 数组
定义：数组（Array）是一种线性表数据结构。它用一组**连续的内存空间**，来存储一组具有相同类型的数据。  
第一是线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。  
第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“随机访问”。

有个表达上的注意：数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。

插入和删除操作的平均时间复杂度是O(n)，但在某些情况下可以进行优化  
1. 插入操作如果相对位置并不重要，未来避免大规模搬运数据，可以将目标插入位置的数据挪到最后，这样就可以实现O(1)的操作
2. 删除操作若不追求数据的连续性，可以将多次删除操作集中到一次，可以提高效率


### 容器和数组对比
容器优势：  
1. 将数组的操作细节都封装起来，操作简单
2. 支持动态扩容  

但容器使用需要注意扩容过程涉及内存申请和数据搬运，所以如果事先知道存储的数据大小，最好指定容器大小。  
如果数据大小事先已知并且操作简单可以直接使用数组。业务开发一般使用容器即可，底层开发或者需要极致性能，可以数组。  


## 链表

### 链表结构
- 单链表
   - 结点
   - 后继指针
   - 头节点
   - 尾结点
- 循环链表
- 双向链表
    - 前驱指针
- 双向循环链表

### 链表和数组对比
- 数组的插入删除是O(n)，随机访问是O(1)，链表正相反
- 数组简单易用，可以借助cpu缓存，访问效率更高，但是大小连续固定，如果申请过大，可能会OOM
- 虽然链表天然支持动态扩缩容，但是频繁操作会导致内存申请和释放频繁，进而可能导致频繁GC

### 如何写好链表
- 理解指针含义：将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。
- 警惕指针丢失和内存泄露：插入结点时，一定要注意操作的顺序
- 利用哨兵简化实现难度：针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。有哨兵后就可统一处理逻辑。有哨兵之后就是**带头链表**
- 重点留意边界条件处理：常用边界条件有链表为空、只有一个结点、只有两个结点、处理头节点和尾结点是否正常
- 举例画图，辅助思考
- 多写多练，没有捷径

写链表代码是最能考验逻辑思维能力的

## 栈
定义：先进后出  
栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。从功能上来说，数组或链表确实可以替代栈，但你要知道，特定的数据结构是对特定场景的抽象，而且，数组或链表暴露了太多的操作接口，操作上的确灵活自由，但使用时就比较不可控，自然也就更容易出错。当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选“栈”这种数据结构。  
栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作**顺序栈**，用链表实现的栈，我们叫作**链式栈**。  

应用场景
- 函数调用栈：操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。我们不一定非要用栈来保存临时变量，只不过如果这个函数调用符合后进先出的特性，用栈这种数据结构来实现，是最顺理成章的选择。
- 表达式求值
- 括号匹配


## 队列
定义：先进者先出，这就是典型的“队列”。  
队列跟栈一样，也是一种操作受限的线性表数据结构。
用数组实现的队列叫作**顺序队列**，用链表实现的队列叫作**链式队列**。

队列类别
- 顺序队列：数组实现
- 链式队列：链表实现
- 循环队列：数组实现时如何判断为空和满的情况, 在判断为满的情况时，最后一个空间不使用
- 阻塞队列：类似于有容量channel
- 并发队列：


## 递归

> 周末你带着女朋友去电影院看电影，女朋友问你，咱们现在坐在第几排啊？电影院里面太黑了，看不清，没法数，现在你怎么办？递归就开始排上用场了。于是你就问前面一排的人他是第几排，你想只要在他的数字上加一，就知道自己在哪一排了。但是，前面的人也看不清啊，所以他也问他前面的人。就这样一排一排往前问，直到问到第一排的人，说我在第一排，然后再这样一排一排再把数字传回来。直到你前面的人告诉你他在哪一排，于是你就知道答案了。  
> 去的过程叫“递”，回来的过程叫“归”

### 递归需要满足三个条件
- 一个问题的解可以分解为几个子问题的解
- 这个问题与分解后的子问题，除了数据规模不同，求解思路完全一样
- 存在递归终止条件

### 如何编写递归代码
写递归代码最关键的是写出**递归公式**，找到**终止条件**。  
对于递归代码，这种**试图想清楚整个递和归过程的做法，实际上是进入了一个思维误区**。如果一个问题 A 可以分解为若干子问题 B、C、D，你可以假设子问题 B、C、D 已经解决，在此基础上思考如何解决问题 A。而且，你只需要思考问题 A 与子问题 B、C、D 两层之间的关系即可，不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。  
编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。  
递归是一种应用非常广泛的算法（或者编程技巧）。之后我们要讲的很多数据结构和算法的编码实现都要用到递归，比如 **DFS 深度优先搜索**、**前中后序二叉树遍历**等等

### 递归弊端
- 堆栈溢出：每调用一个函数，都会将临时变量压入内存栈，等函数执行完成后返回，如果递归求解的数据规模很大，调用层次很深，一直压栈，就会有栈溢出风险。解决方案是限制递归调用深度
- 重复计算：可以用散列表存储已经求解过的问题
- 时间和空间复杂度高：函数调用量较大，内存栈占用过大

### 递归与迭代
递归代码的表达力很强，写起来非常简洁；而弊就是空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用会耗时较多等问题  
通过迭代的方式，类似于手动模拟入栈出栈，通过固定变量减少空间复杂度。但是实现起来会更复杂。
```
// 爬楼梯的递归算法
int f(int n) {
  if (n == 1) return 1;
  if (n == 2) return 2;
  return f(n-1) + f(n-2);
}

// 爬楼梯的迭代算法
int f(int n) {
  if (n == 1) return 1;
  if (n == 2) return 2;
  
  int ret = 0;
  int pre = 2;
  int prepre = 1;
  for (int i = 3; i <= n; ++i) {
    ret = pre + prepre;
    prepre = pre;
    pre = ret;
  }
  return ret;
}

```

## 排序

## 如何分析一个排序算法

1. 执行效率
   - 最好情况、最坏情况、平均情况时间复杂度：有序度不同的数据，对于排序的执行时间肯定是有影响的，我们要知道排序算法在不同数据下的性能表现。
   - 时间复杂度的系数、常数、低阶：实际使用时的数据量可能是几十到几千，这时候系数、常数、低阶都需要考虑进来。在小规模数据面前，O(n^2)时间复杂度的算法并不一定比O(nlogn)的算法执行时间长
   - 比较次数和交换次数：基于对比的算法，需要考虑数据的对比次数和交换次数

2. 内存消耗  
   可以通过空间复杂度来衡量，在排序算法中有一个新的概念“原地排序”，指空间复杂度是O(1)的排序算法

3. 稳定性  
   如果待排序中存在值相等的元素，在排序后相等元素之间原有的先后顺序不变，即是稳定排序
   
### 冒泡
- 原地排序： 是
- 稳定排序：是
- 时间复杂度：最好 O(n) 最坏O(n^2) 平均O(n^2)
  
平均时间复杂度是加权平均期望时间复杂度，这里n个数，就有n!中可能，定量计算起来太复杂。所以引入了下面的“有序度”和“逆序度”进行分析。

**有序度**  
有序元素对：a[i] <= a[j], 如果 i < j。

**逆序度**  
逆序元素对：a[i] > a[j], 如果 i < j。

**满序度**  
对于一个完全有序度数组，有序度是n(n-1)/2，我们把这种完全有序度数组的有序度叫做满有序度。

基于上面三个概念，得到逆序度=满有序度-有序度，我们排序过程就是增加有序度，减少逆序度的过程。

在冒泡排序中，无论算法怎么改进，交换的次数总数确定的，就是逆序度。所以对于n个数据的数组，平均交换次数是n(n-1)/4，所以平均时间复杂度就是O(n)

### 插入排序
- 原地排序： 是
- 稳定排序：是
- 时间复杂度：最好O(n) 最坏O(n^2) 平均O(n^2)
  
### 选择排序
- 原地排序：是
- 稳定排序：否
- 时间复杂度：都是O(n^2)


冒泡排序、选择排序，可能就纯粹停留在理论的层面了，学习的目的也只是为了开拓思维，实际开发中应用并不多，但是插入排序还是挺有用的。后面讲排序优化的时候，我会讲到，有些编程语言中的排序函数的实现原理会用到插入排序算法。

### 归并排序
核心思想：如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。  
归并排序使用的就是分治思想，分治算法一般都是用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧。
> 迭代和递归都是一种编程技巧，在很多地方都有应用

实现递归算法的两步
**递推公式**  
merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))  
**终止条件**  
p >= r 不用再继续分解


- 稳定性：是
- 时间复杂度: O(nlogn)，使用递归共识可计算出
- 空间复杂度： O(n)

### 快速排序

- 原地排序：是
- 稳定性：否 因为分区的过程涉及交换操作，如果数组中有两个相同的元素，比如序列 6，8，7，6，3，5，9，4，在经过第一次分区操作之后，两个 6 的相对先后顺序就会改变
- 时间复杂度：O(nlogn) 只有极度情况下 会变成O(n^2)


桶排序、计数排序、基数排序。因为这些排序算法的时间复杂度是线性的，所以我们把这类排序算法叫作线性排序（Linear sort）。之所以能做到线性的时间复杂度，主要原因是，这三个算法是非基于比较的排序算法，都不涉及元素之间的比较操作。

### 堆排序
todo

### 桶排序
桶排序的时间复杂度是O(n)，但是对排序的要求非常严苛，首先数据很容易划分为m个桶，桶之间有着天然的大小顺序。其次数据在各个桶之间分布是均匀的，如果划分不均匀，就会退化成O(nlogn)

桶排序比较适合用在外部排序中，数据量比较大，内存有限，无法全部加在到内存中。

### 计数排序
计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。比如高考成绩，50w考生，总分900分，那么遍历完考生就可以知道排名了

### 基数排序
基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。

比如手机号码进行排序，利用具有稳定性的排序算法，从最后一位开始比较。最后就可以得到排序好的数据。因为位数只有10个数字，就可以桶排序和计数排序实现O(n)的效率

## 查找




